\chapter{Introduction}
\section{SAT solvers}
\emph{SAT solvers} (shortened from \emph{satisfiability}) are programs which take a boolean satisfiability problem and a find solution or solutions to this problem.
The problem, which we will call an \emph{instance}, consists of a number of variables and boolean clauses composed of these variables.
The solution, if it exists, is an assignment of truth values to the variables such that the clauses are satisfied.
If no such assignment exists the instance is called \emph{unsatisfiable}.

Most modern SAT solvers expect input in \emph{conjunctive normal form} in which all clauses are disjunctions of literals (literal is either a variable or a negation of a variable, and at least one literal must be true) and the instance is a conjunction of such clauses (all clauses must be true).
As the name suggests this is a normal form, which means every boolean expression can be converted to an equivalent one that satisfies these requirements.
Thus we will from now on only consider such instances without loss of generality.

By modeling a decision problem as a SAT instance we can take advantage of the advanced optimizations and heuristics employed by modern SAT solvers.
Examples of such uses in practice include formal program verification, model checking or even routing of connections in microchips.
%TODO refs for use cases

\subsection{Implementation}
Since SAT is an $NP$-complete language and assuming $P \neq NP$ we can not in general find solutions in polynomial time.
A simple exponential time algorithm is to try every possible boolean truth assignment.
To remember which assignments have been tried and which have not we can implement this algorithm as a recursive backtracking, where for every input variable we try in turn both possible values.
This will only require linear memory to implement.

While there are no known algorithms that perform asymptotically better in he worst case, we can still improve on this simple exponential time algorithm significantly by avoiding paths that are guaranteed to lead to a \emph{conflict} -- a partial assignment that can not be extended into any satisfying one.

\subsubsection{DPLL algorithm}
First such improvement is the \emph{DPLL algorithm} (Davis-Putnam-Logemann-Loveland, \citep{davis1960computing,davis1962machine}) which improves upon the naive backtracking algorithm by applying two rules at each step:

\begin{description}
\item[Unit propagation] \hfill \\
We will call a clause a \emph{unit} if it only contains one unassigned literal.
If the clause is already satisfied we can ignore it during further search.
Otherwise it can only be satisfied by assigning the necessary value to the remaining literal.
This means there will be no branching for this literal and thus the search time will be reduced by avoiding the obviously wrong choice.

\item[Pure literal elimination] \hfill \\
We will call a variable \emph{pure} if it only occurs in the formula with a single polarity (that is, always negated or always non-negated).
All pure literals can be assigned the required value to make all clauses containing them true and these clauses can then also be ignored during further search.
\end{description}

These two simple rules will help to reduce the search space the algorithm has to look through and thus reduce the total running time.

\subsubsection{Conflict-Driven Clause Learning}
It can happen that after some partial assignment of variables there is already a conflict and it is not possible to extend this assignment to a satisfying one.
However, the DPLL algorithm will continue to explore the entire search subspace.
With \emph{conflict-driven clause learning} (CDCL, \citep{bayardo1997using,marques1999grasp}) we can avoid this by the use of \emph{implication graph} and \emph{learnt clauses}.

The \emph{implication graph} is a directed graph in which vertices are variables with their assignment.
These will be marked as either \emph{decision} or \emph{forced}.

At first we start with an empty implication graph and execute the DPLL algorithm.
Every time we make an arbitrary decision (the recursive step in the algorithm) we will add a decision vertex representing this variable and the assignment we have chosen into the graph.
Every time either of the two rules of the DPLL algorithm forces some assignment of a variable we will add a forced vertex into the graph, with edges from every vertex that is a part of this forced choice.

For example, with clause $(x \lor y \lor z)$ and with partial assignment $x=0, y=0$ the unit propagation rule will force the assignment of $z=1$.
We will add this as a forced vertex, with edges from both $x=0$ and $y=0$.

When we add an vertex to the graph for some variable but this variable is already present with the opposite assignment we have found a conflict.
Now comes the part of CDCL which speeds up this search -- we will find all the decision vertices (variables) that are responsible for this conflict.
Let us call them $x_1, \dots, x_k$ with assignments $v_1, \dots, v_k$.
From this we can build a \emph{learnt clause} $L$:
\begin{align*}
(x_1 = v_1 \land \dots \land x_k = v_k) &\Rightarrow \bot \\
\overline{\bot} &\Rightarrow \overline{(x_1 = v_1 \land \dots \land x_k = v_k)} \\
\top &\Rightarrow (x_1 = \overline{v_1} \lor \dots \lor x_k = \overline{v_k}) \\
L &:= (x_1^{(\overline{v_1})} \lor \dots \lor x_k^{(\overline{v_k})})
\end{align*}

The notation $x^{(v)}$ is used to represent $x$ if $v=1$ and $\overline{x}$ if $v=0$. Symbols $\top$ and $\bot$ represent tautology and contradiction, respectively.

We can now add this learnt clause $L$ into the list of clauses we have to satisfy, since not satisfying it is guaranteed to lead to a conflict.
In the next step of the backtracking algorithm we will not return only a single level up from the recursion (that is, removing the assigning of just a single variable) but all the way back until we reach the first point where one of the conflicting variables was assigned a value.

This method is used in all modern SAT solvers and improves their performance significantly over the DPLL algorithm.

\subsection{Interfacing with SAT solvers}
\label{sec:dimacs}
Since our work depends on providing a suitable input to SAT solvers we will briefly describe the widely supported \emph{DIMACS\footnote{As in the case of \emph{JPEG} the acronym refers to the institute that created the format -- the \emph{Center for Discrete Mathematics and Theoretical Computer Science.}} CNF} format which we use.
Later in section \ref{sec:branching-order-impl} we will describe augmenting this format for optimization purposes.

The file begins with a line in form

\centerline{\texttt{p cnf $vars$ $clauses$}}

\noindent where $vars$ and $clauses$ are the number of variables and clauses in this instance, respectively.

The following lines are in the form

\centerline{\texttt{$v_1$\dots$v_i$ 0}}

\noindent and each represents a single clause consisting of a disjunction of literals $v_1$ through $v_i$.
Each literal $v_i$ is an integer between $1$ and $vars$ for a variable in positive polarity or an integer between $-1$ and $-vars$ for negative polarity.

The output for a satisfiable instance is a list of $vars$ numbers.
For every $1 \le v_i \le vars$ either $v_i$ or $-v_i$ is present in the list, indicating the polarity of the $i$-th variable in some satisfying assignment. 

\section{Cryptographic problems}
We make use of SAT solvers to find solutions to instances which represent a cryptographic primitive.
The variables represent the inputs, outputs and the internal state of the primitive.
The clauses describe the behavior of the primitive as a relation between the variables.
Solutions to such instances are pairs of inputs and corresponding outputs.

By placing additional restrictions on the possible solutions (by introducing more clauses) we can find a truth assignment that gives us the desired inputs and outputs to the cryptographic primitive.
With a cipher this can mean finding the secret key (input) by restricting the output to observed keystream.
With hash functions this can mean reversing the output for a \emph{preimage} attack or finding two different input with the same output (a \emph{collision}).

In our work we will focus specifically on hash functions, which we describe in more detail in the following section.

\subsection{Hash functions}
\label{sec:hash-functions}
A \emph{hash function} is designed to reduce a long input \emph{message} into a shorter, fixed-length \emph{digest} (short from \emph{message digest}, also called \emph{hash}).
The computation in this direction is often designed to be fast and efficient.
However, a \emph{cryptographic} hash function should further have the property that it is infeasible to compute it in the opposite direction -- that is, given a digest to find a message.\footnote{Not \emph{the} message, since there might be multiple input messages that have the same digest.}

By infeasible (or hard) we mean that the computation should take time exponential to some parameters of the hash function and its input, and thus is not practical for sufficient input sizes.

More precisely, hash function $h$ is a function $h: X \to Y$ where $X$ is the (potentially unbounded) set of input messages and $h(x) \in Y = \{0,1\}^n$ is an $n$-bit message digest.
For a more formal discussion of hash functions (which is beyond the scope of our work) we refer the reader to \cite{rogaway2004cryptographic}.

The properties which we require these functions to have are:

\textbf{Preimage resistance:} Given a digest $d$ it is hard to find a message $m$ such that $h(m) = d$.

\textbf{Second preimage resistance:} Given a message $m_1$ it is hard to find a message $m_2 \neq m_1$ such that $h(m_1) = h(m_2)$.

\textbf{Collision resistance:} It is hard to find messages $m_1,m_2$ such that $h(m_1) = h(m_2)$ and $m_1 \neq m_2$.

%It is easy to see that when a hash function lacks one of these properties it also lacks all the following ones.

Most modern hash functions have multiple rounds in which the state is modified using a \emph{round function}.
Starting from the initial state (usually some constant) a part of the input message (with some form of padding) is processed and a new state produced.
This is repeated until the whole input has been processed and the final state is then used to produce the digest.

\subsubsection{Reduced hash functions and partial attacks}
The expected time to find a preimage for actual hash functions as used in practical cryptography is usually so large we couldn't obtain a solution in a reasonable time.
For this reason we will be working with \emph{reduced} instances of hash functions -- modifications that are similar but easier to attack.
To create such reduced instances we can simply lower the number of rounds used in the computation.

Similarly, finding a full preimage where all the output digest bits are fixed to a certain value could take a long time.
Instead we will focus on \emph{partial} preimage attacks, where only a certain number of output digest bits are fixed.

\subsubsection{The SHA hash functions}
We will briefly describe two hash functions on which we focus in our work and to whose internals we will be referring later.

\textbf{SHA-1}, short for \emph{Secure Hash Algorithm} \cite{NIST1995FIPS180-1} is a widely used hash function based on the \emph{Merkle-Damg\aa rd} construction \cite{merkle1979secrecy} with output digest size of $160$ bits.
%TODO cite standard
The internal state consists of five $32$-bit words $A, B, C, D$ and $E$ which are updated in $80$ rounds.

After padding the message to a length that is multiple of $512$ bits, it is processed in \emph{chunks} of that same size.
Each chunk is broken into $16$ $32$-bit words $W_0, \dots, W_{15}$.
From those $64$ additional words $W_{16}, \dots, W_{79}$ are created by \emph{extending} the chunk:
\[
W_i = (W_{i-3} \oplus W_{i-8} \oplus W_{i-14} \oplus W_{i-16}) \lll 1 ~~~ (16 \le i < 80)
\]
where $\lll$ means cyclic left shift on $32$-bit words.

These words are then processed in $80$ rounds, during which the internal state is updated.
In each round $i$, first the values $f$ and $k$ are computed based on the round number.
Then $T$ is computed as
\[
T = (A \lll 5) + f + E + k + W_i
\]
where addition is performed modulo $2^{32}$.

Finally, the state is updated as follows
\begin{align*}
E \gets D& &D \gets C& &C \gets B \lll 30& &B \gets A& &A \gets T
\end{align*}

The value of $k$ is one of four constants, depending on the value of $\lfloor \frac{i}{20} \rfloor$ (that is, one value for rounds $0$ to $19$, another for rounds $20$ to $39$ and so on).
Similarly, $f$ is computed by one of four \emph{round functions}:

\begin{align*}
f_0 &= Ch(B, C, D) = (B \land C) \oplus (\overline{B} \land D) \\
f_1 = f_3 &= B \oplus C \oplus D \\
f_2 &= Maj(B, C, D) = (B \land C) \oplus (B \land D) \oplus (C \land D)\\
f &= f_{\lfloor \frac{i}{20} \rfloor}
\end{align*}

After processing all chunks the resulting state is the output digest.

~\\

\textbf{SHA-3} is a recently standardized \cite{NIST2015FIPS202} hash function family based on the \emph{Keccak} family \cite{bertoni2011keccak} that won the selection competition against fifty other candidates.
It is based on a \emph{sponge} construction which allows the output digest size to be variable.

We will specifically focus on the variant \emph{SHA-3-512} which has $1600$-bit state updated in $24$ rounds (divided into five steps called $\theta, \rho, \pi, \chi$ and $\iota$) and produces a $512$-bit digest.
%TODO cite standard
The state is represented as a $5\times 5$ matrix $S$ of $64$-bit words.
%Each round consists of five steps called $\theta, \rho, \pi, \chi$ and $\iota$ that first populate matrices and vectors $B, C$ and $D$ using the $S$ matrix from previous round and then use them to create the new $S$ matrix.

We will describe the steps $\theta$ and $\chi$ in little more detail since we will be referring to them later in section \ref{sec:sha3-espresso}.
In the $\theta$ step an auxiliary array $C$ is filled as follows:
\[
C_i = S_{i,0} \oplus S_{i,1} \oplus S_{i,2} \oplus S_{i,3} \oplus S_{i,4} ~~~ (0 \le i < 5)
\]
This is then used, along with two additional arrays $B$ and $D$ to compute the new values of the state $S$ in the $\chi$ step:
\[
A_{i,j} = B_{i,j} \oplus (\overline{B_{i+1,j}} \land B_{i+2,j}) ~~~ (0 \le i,j < 5)
\]

The most important difference compared to SHA-1 is that not the whole state is used for output.
Instead it is divided into two parts: the $576$-bit \emph{bitrate} and $1024$-bit \emph{capacity}, and only the bitrate part is used for the output while the capacity part stays hidden.

The sponge construction then works in two phases -- \emph{absorbing} and \emph{squeezing}.
During absorbing, chunks of the padded input message are xored with the state and the $24$ rounds are performed until the message is fully processed.
Afterwards the bitrate part of the state is used for the output digest.
If it is not long enough another series of $24$ rounds is performed on the whole state and the resulting bitrate part is appended to the digest and so on until the desired length is reached.

This flexible design allows arbitrary output digest sizes for specific applications.
It also makes reversing the process harder, since the entire output state is not known.

\section{Encoding}
The most important step when using SAT solvers for any problem is the encoding of the model to a suitable instance.
In case of cryptographic problems this previously (see section \ref{sec:related-work}) required significant effort of either generating the SAT instance by hand, or by first translating the model to a more suitable form and then using existing tools to generate the instance.

In our work we created a library \cite{papay2016code} which automates large parts of this process.
This makes it easier, faster and less error-prone.
To achieve this we made use of \emph{boolean circuit} representation to translate almost unmodified implementations of cryptographic primitives to SAT instances transparently.

\subsection{Boolean circuits}
The cryptographic primitive we want to encode into a SAT instance can be thought of as a \emph{boolean circuit} -- a \emph{DAG} (directed acyclic graph) in which vertices are boolean operators (\emph{gates}, such as the \emph{AND gate}, \emph{XOR gate} and so on).
The edges represent flow of values from one gate to another.
\emph{Inputs} are special vertices that have no incoming edges.
\emph{Outputs} are also special vertices that have exactly one incoming edge and no outgoing edges.

Given this representation the simplest way to encode this as a CNF formula would be to take each output vertex and recursively expand it in the following way:
At first we start with an output vertex $v$ encoded as $(v)$.
This will have one incoming edge from a gate vertex $g$ with inputs $x_1, \dots, x_k$.
We will encode this as $g(x_1, \dots, x_k)$ where $g$ is the appropriate boolean operation of the gate -- for example, if the output vertex is connected to an \emph{AND} gate this would be $(x_1 \land \dots \land x_k)$.

Now we repeat this process recursively, expanding each gate node until the encoding only refers to the input vertices.
The resulting encoding has to be converted into conjunctive normal form and can then be solved with any SAT solver.

However, this approach produces very large output formula with many clauses.
Since we are recursively expanding each vertex until we reach the input vertices, large subgraphs which are referenced (connected by an outgoing edge) multiple times will needlessly be repeated in the output encoding.
The total length of the formula then can be exponential in the size of the input circuit.
%TODO exponential example

\subsection{Tseitin transformation}
\label{sec:tseitin}
To reduce the number of clauses of the resulting encoding we can use the \emph{Tseitin transformation} \cite{tseitin1983complexity}.
Instead of generating a large number of clauses when expanding the circuit we will add a new variable for each vertex.

Each gate vertex can then be encoded as a boolean function with constant number of clauses using only variables corresponding to gates (or inputs) that are connected via an incoming edge.
The following table shows how to encode the most common boolean gates with two inputs $A$ and $B$.
Variable $C$ refers to the new variable representing this gate in the encoding.

\begin{tabular}{r c l}
\emph{AND}& $A\land B$ & $(C \lor \overline{A} \lor \overline{B}) \land (\overline{C} \lor A) \land (\overline{C} \lor B)$ \\
\emph{OR} & $A\lor B$ & $(\overline{C} \lor A \lor B) \land (C \lor \overline{A}) \land (C \lor \overline{B})$ \\
\emph{XOR} & $A\oplus B$ & $(\overline{C} \lor \overline{A} \lor \overline{B}) \land (\overline{C} \lor A \lor B) \land$\\
& & $(C \lor \overline{A} \lor B) \land (C \lor A \lor \overline{B})$
\end{tabular}

Other binary gates such as \emph{NAND} can be encoded similarly.
In case of multiple inputs we can either extend this encoding or replace the $n$-ary gates with multiple binary ones.
%However, the \emph{XOR} gate will have number of clauses exponential in the number of variables.

This encoding produces formula with linear number of variables and linear length with respect to the size of the boolean circuit, if we limit it to unary and binary gates.

\subsection{Arithmetic gates}
Most cryptographic algorithms make heavy use of arithmetic operations, such as modular addition.
These usually work on variables of some fixed size, for example 32-bit integers.

The $n$-bit variable can be represented using $n$ binary variables in the SAT instance.
However, these operations can not be performed on individual bits like in the case of boolean operators.
We need to introduce additional helper variables that will represent the carry bits during the addition operation.

This can be thought of as taking the boolean circuit for a binary adder with carry (either ripple-carry or lookahead-carry), composed of several full-adder circuits.
These can then be encoded using the Tseitin transformation.

However, for simplicity we extend our model of boolean circuits to support modular addition nodes directly.
When encoding these nodes to CNF we use the additional carry variables and output the clauses required to model a binary adder.

\section{Related work}
\label{sec:related-work}
The idea of using SAT solvers for cryptographic problems was first introduced in \cite{massacci2000logical}.
The authors designed an encoding of the \emph{DES} (\emph{Data Encryption Standard}) symmetric cipher and created a program to generate instances.
However the work is very specific to \emph{DES} and modifying the tool for a different cipher would require significant changes.

The first attempt to simplify this process can be found in \cite{jovanovic2005logical} where \emph{operator overloading} (see section \ref{sec:operator-overloading}) in the \emph{C++} language is used.
Our library also makes use of this feature with the additional advantage that we use a \emph{dynamic} programming language (\emph{Python}) and therefore require smaller changes to existing code.
Additionally their work uses only simple Tseitin transform without additional optimizations, and the code for the tool is not available.

Another work which automates the generation of instances makes use of the \emph{Verilog} hardware description language\footnote{HDLs describe the behavior of logic circuits. They are used for programming FPGAs or designing ASICs.} \cite{morawiecki2013sat}.
After writing the cryptographic primitive in this language a free, but proprietary, compiler is used to generate equations which are then turned to a CNF instance.
Since \emph{Verilog} is quite a niche language most cryptographic primitives do not have implementations available.
Additionally the toolkit itself is also not publicly available.

An in-depth analysis of \emph{SHA-1} preimage attacks was done in \cite{nossum2012sat}.
The instances were generated using a custom, hand-built 1000-line \emph{C++} program.
The experiments investigated the speed of various SAT solvers, effects of preprocessing and simplifying the instance and various heuristics.


% sat solvers
%  - solve any decision problem
%  - input usualy as cnf
%  - DIMACS format example and semantics (move here?)
%  - advanced heuristics etc
%  - DPLL / ... ? if too short
%
% crypto problems
%  - decision problems as well, can use sat
%  - will focus on hash functions
%
% hash functions
%  - basic idea
%  - attacks
%  - reduced rounds
%  - relevant functions for us (sha family)
% 
% existing work survey